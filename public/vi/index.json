[
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/1-introduce/",
	"title": "Giới thiệu",
	"tags": [],
	"description": "",
	"content": "Bối cảnh và Động lực Trong thời đại dữ liệu bùng nổ, việc xử lý và phân tích dữ liệu một cách hiệu quả, tự động, và có khả năng mở rộng linh hoạt là yếu tố then chốt giúp các tổ chức hiện đại đưa ra quyết định kịp thời và tối ưu quy trình kinh doanh.\nĐề tài “Xây dựng Serverless Data Processing Pipeline với AWS Step Functions và Amazon EventBridge” trình bày một giải pháp xử lý dữ liệu không máy chủ (serverless), tận dụng sức mạnh của các dịch vụ Amazon Web Services (AWS) nhằm đáp ứng các yêu cầu về hiệu suất, độ linh hoạt và tối ưu chi phí.\nPipeline được thiết kế để tự động xử lý các tệp CSV được tải lên Amazon S3, sử dụng Amazon EventBridge để kích hoạt quy trình khi phát hiện tệp mới, và AWS Step Functions để điều phối từng bước xử lý — bao gồm kiểm tra định dạng, xử lý song song, tổng hợp kết quả và lưu trữ.\nCác tác vụ xử lý được thực hiện bởi các hàm AWS Lambda. Metadata được lưu vào Amazon DynamoDB, thông báo trạng thái được gửi qua Amazon SNS, và toàn bộ hệ thống được giám sát bởi Amazon CloudWatch để đảm bảo hiệu suất và phát hiện lỗi kịp thời.\nƯu điểm của Giải pháp Serverless với Step Functions và EventBridge Hệ thống sử dụng các dịch vụ chủ lực như Amazon S3, EventBridge, Step Functions, Lambda, DynamoDB, CloudWatch, và SNS, đem lại nhiều lợi ích nổi bật:\nTự động hóa hoàn toàn:\nQuy trình được kích hoạt và điều phối tự động dựa trên sự kiện.\nKhả năng mở rộng linh hoạt:\nTự động điều chỉnh theo khối lượng công việc, hỗ trợ xử lý song song.\nTối ưu chi phí vận hành:\nMô hình trả phí theo mức sử dụng, không cần duy trì hạ tầng vật lý.\nXử lý lỗi thông minh:\nLogic retry tự động, thông báo lỗi qua SNS và theo dõi lỗi qua CloudWatch.\nLinh hoạt \u0026amp; dễ bảo trì:\nWorkflow dễ dàng cập nhật, tách biệt các chức năng bằng Lambda.\nGiám sát hiệu quả:\nCloudWatch cung cấp log và cảnh báo theo thời gian thực.\nXác thực dữ liệu đầu vào:\nĐảm bảo dữ liệu hợp lệ trước khi xử lý.\nVận hành đơn giản:\nDễ dàng quản lý vòng đời tài nguyên: tạo, cập nhật, xóa.\nPhù hợp thực tiễn:\nÁp dụng tốt cho nhiều tình huống như ETL, phân tích dữ liệu theo lô, hệ thống phân tích sự kiện thời gian thực.\n"
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/",
	"title": "Serverless Data Processing Pipeline",
	"tags": [],
	"description": "",
	"content": "Xây dựng Pipeline Xử lý Dữ liệu Serverless với AWS Step Functions và EventBridge 📌 Tổng quan Trong bối cảnh công nghệ hiện đại, nhu cầu xử lý dữ liệu lớn một cách hiệu quả, linh hoạt và tiết kiệm chi phí ngày càng trở nên cấp thiết. Các tổ chức và doanh nghiệp cần những giải pháp có khả năng mở rộng linh hoạt, dễ quản lý, và loại bỏ gánh nặng vận hành hạ tầng phức tạp.\nCông nghệ serverless trên nền tảng đám mây đã nổi lên như một hướng đi tối ưu, cho phép xây dựng các hệ thống xử lý dữ liệu mạnh mẽ mà không cần quản lý máy chủ vật lý, từ đó giảm thiểu chi phí vận hành, tăng tốc độ triển khai và khả năng tự động hóa cao.\n🧩 Mô tả tổng quan pipeline Pipeline serverless này xử lý dữ liệu từ các tệp CSV được tải lên Amazon S3. Amazon EventBridge nhận sự kiện từ S3, lọc các tệp .csv, và kích hoạt AWS Step Functions để điều phối các bước xử lý. AWS Lambda thực hiện các tác vụ như xác thực, xử lý song song, tổng hợp, và lưu kết quả. Amazon DynamoDB lưu metadata, Amazon CloudWatch giám sát hiệu suất và lỗi, Amazon SNS gửi thông báo email về trạng thái pipeline.\nTất cả được triển khai tại Region Singapore (ap-southeast-1).\n🧱 Các thành phần chính Amazon S3\nInput Bucket: Lưu trữ tệp CSV đầu vào\ndata-processing-input-\u0026lt;your-account-id\u0026gt; Output Bucket: Lưu trữ kết quả JSON\ndata-processing-output-\u0026lt;your-account-id\u0026gt; Amazon EventBridge\nLọc sự kiện ObjectCreated từ S3 cho các tệp .csv và kích hoạt Step Functions AWS Step Functions (State Machine: DataProcessingWorkflow)\nValidateData: Kiểm tra tính hợp lệ của tệp CSV ParallelProcess: Xử lý song song hai nhánh (ProcessData1, ProcessData2) AggregateData: Tổng hợp kết quả từ các nhánh song song StoreResults: Lưu kết quả vào S3 và metadata vào DynamoDB NotifySuccess: Gửi thông báo thành công qua SNS ErrorHandler: Gửi thông báo lỗi qua SNS AWS Lambda\nValidateDataFunction: Kiểm tra định dạng CSV ProcessDataFunction: Xử lý dữ liệu (gọi trong các nhánh song song) AggregateDataFunction: Tổng hợp kết quả StoreResultsFunction: Lưu kết quả và metadata Amazon DynamoDB\nBảng ProcessingMetadata lưu thông tin như: ExecutionId, Timestamp, Status Amazon CloudWatch\nGhi log và thiết lập cảnh báo khi có lỗi Amazon SNS\nTopic: PipelineNotifications gửi email thông báo trạng thái IAM Roles\nLambdaDataProcessingRole: Quyền cho Lambda truy cập S3, DynamoDB, SNS StepFunctionsDataProcessingRole: Quyền cho Step Functions gọi Lambda và SNS 🔁 Luồng dữ liệu Người dùng tải tệp CSV (ví dụ: test.csv) lên S3 Input Bucket\nS3 tạo sự kiện ObjectCreated, gửi đến EventBridge\nEventBridge Rule (S3TriggerRule) lọc tệp .csv và kích hoạt Step Functions (DataProcessingWorkflow)\nStep Functions điều phối:\nValidateData: Gọi ValidateDataFunction để kiểm tra CSV ParallelProcess: Chạy hai nhánh song song, mỗi nhánh gọi ProcessDataFunction AggregateData: Gọi AggregateDataFunction để tổng hợp kết quả StoreResults: Gọi StoreResultsFunction để lưu vào S3 Output Bucket và DynamoDB NotifySuccess: Gửi thông báo thành công qua SNS ErrorHandler: Gửi thông báo lỗi qua SNS nếu có lỗi ở bất kỳ bước nào CloudWatch ghi log và kích hoạt cảnh báo nếu có lỗi\nSNS gửi email thông báo trạng thái pipeline (thành công hoặc lỗi)\nNội dung Giới thiệu Các bước chuẩn bị Tạo kết nối đến máy chủ EC2 Quản lý session logs Port Forwarding Dọn dẹp tài nguyên "
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/2-preparation/",
	"title": "Chuẩn bị",
	"tags": [],
	"description": "",
	"content": "Các Bước Chuẩn Bị 1. Tạo Các Thành Phần IAM Bước 1: Tạo IAM User Group Truy cập AWS Console: https://console.aws.amazon.com/iam Chọn User groups → Create group Đặt tên nhóm: devGr Gán quyền: Chọn policy có sẵn: AdministratorAccess Nhấn Create group Bước 2: Tạo IAM User Truy cập mục Users → chọn Add users Nhập tên: dev-user Chọn Access Type: Programmatic access (để dùng AWS CLI) AWS Management Console access (để đăng nhập web) Thiết lập mật khẩu hoặc để AWS tạo ngẫu nhiên Thêm user vào group: chọn devGr Nhấn Create user Bước 3: Tạo AWS Access Key Trong danh sách users, click vào user dev-user Chuyển sang tab Security credentials Ở mục Access keys, nhấn Create access key Chọn mục đích sử dụng: CLI Sau khi tạo thành công, bạn sẽ nhận: Access key ID Secret access key ⚠️ Lưu lại ngay, vì bạn chỉ thấy Secret access key duy nhất một lần! 2. Cài Đặt và Cấu Hình AWS CLI Cài Đặt AWS CLI trên Windows Mở hộp thoại Run (Windows + R), dán lệnh sau để tải và cài: msiexec.exe /i https://awscli.amazonaws.com/AWSCLIV2.msi Kiểm Tra Phiên Bản CLI aws --version Cấu Hình CLI aws configure Nhập các thông tin sau:\n\u0026ndash; Access Key ID\n\u0026ndash; Secret Access Key\n\u0026ndash; Region (ví dụ: ap-southeast-1)\n\u0026ndash; Output format (ví dụ: json)\n3. Tạo Tệp CSV Tạo File CSV Nhấn Windows + R → gõ notepad\nDán nội dung sau:\nid,name,amount 1,John,100 2,Jane,200 Chọn Save As:\nTên file: test.csv\nSave as type: All Files (.)\nEncoding: UTF-8\nĐảm bảo không lưu thành .txt\n"
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/3-creates3/",
	"title": "Tạo S3 Buckets",
	"tags": [],
	"description": "",
	"content": "☁️ Bước 1: Tạo S3 Buckets Amazon S3 được sử dụng để lưu trữ dữ liệu đầu vào (input) và đầu ra (output) cho pipeline xử lý dữ liệu.\n1. Truy cập S3 Console Vào AWS Console: https://console.aws.amazon.com/s3 Gõ S3 vào thanh tìm kiếm và chọn Amazon S3 2. Tạo Bucket Đầu Vào (Input Bucket) Nhấn Create bucket\nThiết lập thông tin:\nBucket name: data-processing-input-123456789012\n(thay 123456789012 bằng AWS Account ID của bạn)\nRegion: Chọn Asia Pacific (Singapore) - ap-southeast-1\nObject Ownership: Chọn ACLs disabled\nBlock Public Access: Giữ mặc định (chặn tất cả truy cập công khai)\nEncryption: Bật Enable với tùy chọn\nServer-side encryption with Amazon S3-managed keys (SSE-S3)\nNhấn Create bucket\n⚠️ Nếu gặp lỗi \u0026quot;Bucket name already exists\u0026quot;, hãy thêm hậu tố ngẫu nhiên, ví dụ:\ndata-processing-input-123456789012-v1\n3. Tạo Bucket Đầu Ra (Output Bucket) Lặp lại các bước trên để tạo bucket: Bucket name: data-processing-output-123456789012 4. Kiểm Tra Bucket Vào tab Buckets, xác nhận đã tạo được cả: data-processing-input-123456789012 data-processing-output-123456789012 Tùy Chọn: Tải file test.csv lên Input Bucket Vào bucket data-processing-input-123456789012 Nhấn Upload Chọn file test.csv đã tạo trước đó Nhấn Upload để tải lên "
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/4-create-iam-roles/",
	"title": "Tạo IAM Roles",
	"tags": [],
	"description": "",
	"content": "Bước 2: Tạo IAM Roles IAM Roles dùng để cấp quyền truy cập cho các dịch vụ AWS Lambda và AWS Step Functions trong quá trình xử lý dữ liệu.\n1. Truy cập IAM Console Vào AWS Console: https://console.aws.amazon.com/iam Tìm IAM → chọn Roles → nhấn Create role 2. Tạo Role Cho Lambda Trusted entity type: Chọn AWS service → chọn Lambda Nhấn Next Gán Permissions: Nhấn Add permissions\nTìm và chọn các policy sau:\nAWSLambdaBasicExecutionRole (ghi log lên CloudWatch) AmazonS3FullAccess (quyền truy cập S3) AmazonDynamoDBFullAccess (truy cập DynamoDB) AmazonSNSFullAccess (gửi thông báo qua SNS) 🔒 Khuyến nghị bảo mật: Thay vì dùng FullAccess, nên tạo chính sách tuỳ chỉnh giới hạn quyền theo tài nguyên cụ thể (nêu ở phần sau)\nNhấn Next → đặt tên role: LambdaDataProcessingRole Nhấn Create role 3. Tạo Role Cho Step Functions Quay lại IAM \u0026gt; Roles → Create role Trusted entity type: Chọn AWS service → chọn Step Functions Nhấn Next Gán Permissions: Tìm và chọn các policy sau:\nAWSLambdaFullAccess (để Step Functions gọi Lambda) AmazonS3FullAccess AmazonDynamoDBFullAccess CloudWatchLogsFullAccess AmazonSNSFullAccess Nhấn Next → đặt tên role: StepFunctionsDataProcessingRole\nNhấn Create role\n4. Kiểm Tra Roles Truy cập IAM \u0026gt; Roles\nTìm và xác nhận đã tạo 2 role:\nLambdaDataProcessingRole StepFunctionsDataProcessingRole "
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/6-cleanup/",
	"title": "Dọn dẹp tài nguyên  ",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost:1313/ws_FCJ_HoangNam/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]